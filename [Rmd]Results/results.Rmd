---
title: 'Result notes for "Temporal dynamics of auditory bistable perception correlated with a fluctuation of baseline pupil size"'
author: "Yuta Suzuki, Hsin-I Liao, Shigeto Furukawa"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  word_document:
    reference_docx: doc_templete.docx
  # html_document:
  #   css: style.css
# mainfont: Times New Roman
# draft: yes
---


---

*Corresponding author: Yuta Suzuki
NTT Communication Science Laboratories, NTT Corporation, Atsugi 243-0198, Japan
Tel: +81-046-240-3525, 
E-mail: yuuta.suzuki.fc@hco.ntt.co.jp


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# tinytex::install_tinytex()
```

```{r, message=FALSE, warning=FALSE, echo=FALSE, include=FALSE}


mmFlg = FALSE
auFlg = FALSE

if(mmFlg){
  load("./data/Exp1/figure2_mm.rda")
}else if(auFlg){
  load("./data/Exp1/figure2_au.rda")
}else{
  load("./data/Exp1/figure2_norm.rda")
}

numOfsub = length(unique(data_res_tonic$sub))
anovaTabAll_e1 = list()

#### Behavioral(# of trials) ----------------------------------------------------------------
ave_numOfTrial = aggregate( numOfTrial ~ numOfSwitch, data = data_numOfTrial, FUN = "mean")
ave_numOfTrial$numOfTrial = round(ave_numOfTrial$numOfTrial,2)
sd_numOfTrial = aggregate( numOfTrial ~ numOfSwitch, data = data_numOfTrial, FUN = "sd")
sd_numOfTrial$numOfTrial = round(sd_numOfTrial$numOfTrial,2)
anovakun(data_numOfTrial,"sA",long=T, peta=T,gg=T)

data_numOfTrial$numOfSwitch = factor(data_numOfTrial$numOfSwitch,levels = unique(data_numOfTrial$numOfSwitch))
data_numOfTrial$sub = factor(data_numOfTrial$sub,levels = unique(data_numOfTrial$sub))

numOfTrial_BF = anovaBF(numOfTrial ~ numOfSwitch + sub, data=data_numOfTrial, whichRandom = "sub",progress=FALSE)

x = data_numOfTrial[data_numOfTrial$numOfSwitch == "2+",]$numOfTrial
y = data_numOfTrial[data_numOfTrial$numOfSwitch == "1",]$numOfTrial
n = length(x)
ttest_pair1_2 = t.test(x, y, paired=TRUE)
bayesF_pair1_2 = ttestBF(x = x, y = y, paired=TRUE)

x = data_numOfTrial[data_numOfTrial$numOfSwitch == "1",]$numOfTrial
y = data_numOfTrial[data_numOfTrial$numOfSwitch == "0",]$numOfTrial

ttest_pair0_1 = t.test(x, y, paired=TRUE)
bayesF_pair0_1 = ttestBF(x = x, y = y, paired=TRUE)

x = data_numOfTrial[data_numOfTrial$numOfSwitch == "2+",]$numOfTrial
y = data_numOfTrial[data_numOfTrial$numOfSwitch == "0",]$numOfTrial

ttest_pair0_2 = t.test(x, y, paired=TRUE)
bayesF_pair0_2 = ttestBF(x = x, y = y, paired=TRUE)

numOfTrial = list(list(
  anovaTab = forDrawingSigANOVA,
  post = forDrawingPost[["A"]][["bontab"]],
  bf = round(exp(numOfTrial_BF@bayesFactor[["bf"]]),3),
  cohen_pair1_2 = abs(round(ttest_pair1_2[["statistic"]][["t"]] / sqrt(n),3)),
  bayesF_pair1_2 = round(exp(bayesF_pair1_2@bayesFactor[["bf"]]),3),
  cohen_pair0_1 = abs(round(ttest_pair0_1[["statistic"]][["t"]] / sqrt(n),3)),
  bayesF_pair0_1 = round(exp(bayesF_pair0_1@bayesFactor[["bf"]]),3),
  cohen_pair0_2 = abs(round(ttest_pair0_2[["statistic"]][["t"]] / sqrt(n),3)),
  bayesF_pair0_2 = round(exp(bayesF_pair0_2@bayesFactor[["bf"]]),3)

))
names(numOfTrial) <- c('numOfTrial')
anovaTabAll_e1 = c(anovaTabAll_e1,numOfTrial)

#### Behavioral(number of switch and jitter) ------------------------------------------------------
saveLoc = "../[Python]PreProcessing/Exp1/data/"
dat_jitter=fromJSON(file=paste(saveLoc,"numOfSwitch_jitter.json", sep = ""))

ind_jitter <- data.frame(
  sub = unlist(dat_jitter$sub),
  numOfSwitch = unlist(dat_jitter$numOfSwitch),
  jitter = unlist(dat_jitter$taskTimeLen)
)
dat_jitter = aggregate( . ~ sub*numOfSwitch, data = ind_jitter, FUN = "mean")
anovakun(dat_jitter,"sA",long=T, peta=T,gg=T)

dat_jitter$numOfSwitch = factor(dat_jitter$numOfSwitch,levels = unique(dat_jitter$numOfSwitch))
dat_jitter$sub = factor(dat_jitter$sub,levels = unique(dat_jitter$sub))

bf = anovaBF(jitter ~ numOfSwitch + sub, data=dat_jitter, whichRandom = "sub",progress=FALSE)

jitter_table = list(list(
  anovaTab = forDrawingSigANOVA,
  post = forDrawingPost[["A"]][["bontab"]],
  bf = round(exp(bf@bayesFactor[["bf"]]),3)
))
names(jitter_table) <- c('jitter_table')

anovaTabAll_e1 = c(anovaTabAll_e1,jitter_table)

#### Behavioral(RT) --------------------------------------------------------------------
anovakun(data_RT,"sA",long=T, peta=T,gg=T)
rt_sd = aggregate( RT ~ numOfSwitch, data = data_RT, FUN = "sd")
rt_ave = aggregate( RT ~ numOfSwitch, data = data_RT, FUN = "mean")
rt_sd$RT = round(rt_sd$RT,3)
rt_ave$RT = round(rt_ave$RT,3)

data_RT$numOfSwitch = factor(data_RT$numOfSwitch,levels = unique(data_RT$numOfSwitch))
data_RT$sub = factor(data_RT$sub,levels = unique(data_RT$sub))

bf = anovaBF(RT ~ numOfSwitch + sub, data=data_RT, whichRandom = "sub",progress=FALSE)

RT_table = list(list(
  anovaTab = forDrawingSigANOVA,
  post = forDrawingPost[["A"]][["bontab"]],
  bf = round(exp(bf@bayesFactor[["bf"]]),3)
))
names(RT_table) <- c('RT_table')

anovaTabAll_e1 = c(anovaTabAll_e1,RT_table)

#### Figure 2A(average baseline pupil size) ------------------------------------------------------
data_res_tonic$data_y = data_res_tonic$Size
data_res_tonic$Size = NULL
anovakun(data_res_tonic,"sA",long=T, peta=T,gg=T)

data_res_tonic$numOfSwitch = factor(data_res_tonic$numOfSwitch,levels = unique(data_res_tonic$numOfSwitch))
data_res_tonic$sub = factor(data_res_tonic$sub,levels = unique(data_res_tonic$sub))

bf = anovaBF(data_y ~ numOfSwitch + sub, data=data_res_tonic, whichRandom = "sub",progress=FALSE)

x = data_res_tonic[data_res_tonic$numOfSwitch == "2+",]$data_y
y = data_res_tonic[data_res_tonic$numOfSwitch == "0",]$data_y
n = length(x)
# sc = sqrt((n*(var(x))+n*(var(y)))/(n*2))
# cohen_d0 = round(abs(mean(x)-mean(y))/sc,3)
ttest_pair0_2 = t.test(x, y, paired=TRUE)

bayesF = ttestBF(x = x, y = y, paired=TRUE)
bayesF_d0 = round(exp(bayesF@bayesFactor[["bf"]]),3)

x = data_res_tonic[data_res_tonic$numOfSwitch == "2+",]$data_y
y = data_res_tonic[data_res_tonic$numOfSwitch == "1",]$data_y
ttest_pair1_2 = t.test(x, y, paired=TRUE)

# sc = sqrt((n*(var(x))+n*(var(y)))/(n*2))
# cohen_d1 = round(abs(mean(x)-mean(y))/sc,3)
bayesF = ttestBF(x = x, y = y, paired=TRUE)
bayesF_d1 = round(exp(bayesF@bayesFactor[["bf"]]),3)

BP_table = list(list(
  anovaTab = forDrawingSigANOVA,
  post = forDrawingPost[["A"]][["bontab"]],
  bf = round(exp(bf@bayesFactor[["bf"]]),3),
  cohen_d0 = abs(round(ttest_pair0_2[["statistic"]][["t"]] / sqrt(n),3)),
  bayesF_d0 = bayesF_d0,
  cohen_d1 = abs(round(ttest_pair1_2[["statistic"]][["t"]] / sqrt(n),3)),
  bayesF_d1 = bayesF_d1
))
names(BP_table) <- c('BP_table')

anovaTabAll_e1 = c(anovaTabAll_e1,BP_table)

numOfSub = length(unique(data_res_tonic$sub))
f = data.frame(
  sub = as.character(unique(data_res_tonic$sub)),
  y = matrix(data_res_tonic$data_y,nrow = numOfSub)
)

colnames(f) <- c("subject",c('0','1','2+'))
write.csv(f, "../[JASP]Bayesian/BP_e1.csv",row.names=FALSE)

#### Figure 2B (tertile) -----------------------------------------------------------
if(mmFlg){
  data = fromJSON(file="../[Python]PreProcessing/Exp1/data/data_tertile_mm.json")
}else if(auFlg){
  data = fromJSON(file="../[Python]PreProcessing/Exp1/data/data_tertile_au.json")
}else{
  # data = fromJSON(file="../[Python]PreProcessing/Exp1/data/data_tertile.json")
  data = fromJSON(file="../[Python]PreProcessing/Exp1/data/data_tertile_norm.json")
}

data_tertile = data.frame(
  sub = data$sub,
  data_y = data$numOfSwitch_sorted,
  Tertile = data$tertile
)

# data_tertile = data_tertile_e2
x = as.numeric(data_tertile$Tertile)
data_tertile$Tertile = as.numeric(data_tertile$Tertile)

y = data_tertile$data_y
f <- y ~  a*x + b
model1 <- nls(f, start = c(a = 0, b = 0))

f <- y ~  a*x^2 + b*x + c
model2 <- nls(f, start = c(a = 0, b = 0, c=0))

if (AIC(model1) > AIC(model2)){
  model = model2
}else{
  model = model1
}
df <- data.frame(x = seq(1, 5, length = 10))
data_curve = data.frame(
  Tertile = df$x,
  yy = predict(model, df)
)

bf = regressionBF(data_y ~ Tertile, data = data_tertile)
data_tertile = aggregate( . ~ sub*Tertile, data = data_tertile, FUN = "mean")

tertile_table = list(list(
  tVal = round(summary(model)[["coefficients"]]['a',]['t value'],4),
  pVal = round(summary(model)[["coefficients"]]['a',]['Pr(>|t|)'],4),
  bf = round(exp(bf@bayesFactor[["bf"]]),3),
  r = cor.test(x,y),
  model = model
))
names(tertile_table) <- c('tertile_table')

anovaTabAll_e1 = c(anovaTabAll_e1,tertile_table)

# #### Figure 2B (heatmap) ------------------------------------------------------------
data=fromJSON(file="../[Python]PreProcessing/Exp1/heatmap/corr2.json")
melted_data <- melt(data)
p_values=fromJSON(file="../[Python]PreProcessing/Exp1/heatmap/p_values2.json")
melted_p_values <- melt(p_values)
melted_data$p.value = round(melted_p_values$value,3)
melted_data$value = round(melted_data$value,3)

#### Figure 3A (cross-corr) -----------------------------------------------------------
data = fromJSON(file="../[Python]PreProcessing/Exp1/data/data_CCF_trial_norm.json")

dat <- list(matrix(unlist(data$raw),nrow=length(data$raw),byrow=T),
            matrix(unlist(data$raw_queue),nrow=length(data$raw_queue),byrow=T))
names(dat) <- c('trial','seconds')
ggName =  c('shuffled','raw')
numOfTrial = dim(dat$trial)[1]
numOfSub = length(unique(data$sub))
lengthOfTime = dim(dat$trial)[2]

ind_data <- data.frame(
  sub =  rep( data$sub, times = rep( lengthOfTime, numOfTrial)),
  data_y = c(t(matrix(t(dat$trial),nrow=1))),
  condition = rep(ggName[data$randFlag+1], times = rep( lengthOfTime, numOfTrial)),
  data_x = data$lags_trial
)

data_ccorr = aggregate( data_y ~ sub*condition*data_x, data = ind_data, FUN = "mean")
data_ccorr = data_ccorr[order(data_ccorr$sub,data_ccorr$condition),]
t = aggregate( data_y ~ sub*condition, data = data_ccorr, FUN = "max")
maxLag = NULL
for(i in 1 : length(t$data_y)){
  tmp = data.frame(
    sub = t$sub[i],
    condition = t$condition[i],
    data_y = data_ccorr[data_ccorr$data_y == t$data_y[i],]$data_x
  )
  maxLag = rbind(maxLag,tmp)
}

# #### Figure 3B (peak corr.) #####
maxVal = aggregate( data_y ~ sub*condition, data = data_ccorr, FUN = "max")
x = maxVal[maxVal$condition == 'raw',]$data_y
y = maxVal[maxVal$condition == 'shuffled',]$data_y
n = length(x)
sc = sqrt((n*(var(x))+n*(var(y)))/(n*2))
CCF_max_cohen_d = round(abs(mean(x)-mean(y))/sc,3)
CCF_max = t.test(x,y,var.equal=T,paired=T)
CCF_max_bayesF = ttestBF(x = x, y = y, paired=TRUE)
CCF_max_bayesF = round(exp(CCF_max_bayesF@bayesFactor[["bf"]]),3)

# #### Figure 3C (lag at peak corr.) #####
x = maxLag[maxLag$condition == 'raw',]$data_y
CCF_lag_bayesF = ttestBF(x = x)
CCF_lag_bayesF = round(exp(CCF_lag_bayesF@bayesFactor[["bf"]]),3)
CCF_lag = t.test(x, mu=0, alternative="less")

# Figure 3D (LMM) #
# load("./data/Exp1/betaWtFunc.rda")
# data=fromJSON(file="./data/Exp1/data_include_past2.json")
# 
# pVal = NULL
# betaWtFunc = data.frame()
# tmpAIC_model2 = NULL
# tmpAIC_model1 = NULL
# for(i in -20:20){
#   ind_data <- data.frame(
#     sub =  unlist(data$sub),
#     PDR = unlist(data[[paste("PDR_lag",i,sep="")]]),
#     ave = unlist(data[["ave"]]),
#     Baseline = unlist(data[["Baseline"]]),
#     diff = unlist(data[["diff"]]),
#     numOfSwitch = unlist(data[["numOfSwitch"]])
#   )
# 
#   ind_data[ind_data$numOfSwitch > 2,]$numOfSwitch = 2
#   ind_data = ind_data[ind_data$PDR != 0,]
# 
#   model = lmer( numOfSwitch ~ PDR + (1+PDR|sub),ind_data)
#   gt = ranef(model)[["sub"]][["PDR"]]
# 
#   model = summary(model)
# 
#   pVal = rbind(pVal,model[["coefficients"]]['PDR',]['Pr(>|t|)'])
# 
#   subpVal=NULL
#   for(iSub in unique(unlist(data$sub))){
#     tmp  = ind_data[ind_data$sub == iSub,]
#     submodel = lm(numOfSwitch ~ PDR, data = tmp)
#     subpVal = rbind(subpVal,summary(submodel)[["coefficients"]]['PDR',]['Pr(>|t|)'])
#   }
# 
#   betaWt = data.frame(
#     sub = unique(unlist(data$sub)),
#     data_y = gt + model[["coefficients"]]['PDR',]['Estimate'],
#     lag = i,
#     pval = p.adjust(as.numeric(subpVal), method = "BH")
#   )
#   betaWtFunc =  rbind(betaWtFunc,betaWt)
# 
# }
# # save(betaWtFunc, pVal, file = "./data/Exp1/betaWtFunc.rda")
# 
# betaWtFunc$sub = subName[betaWtFunc$sub]
# dat_ave = aggregate( data_y ~ lag, data = betaWtFunc, FUN = "mean")
# dat_ave$sub = 'average'
# dat_ave$pval = p.adjust(pVal, method = "BH")
# res_lmm = dat_ave[dat_ave['pval'] < 0.05,]$lag
# 
# Figure 3E (AUC) 
# data=fromJSON(file="./data/Exp1/roc_past2.json")
# 
# ggName = c('Baseline','Transient')
# ggName2 = c('e1','e2')
# dat <- list((matrix(unlist(data$FalsePos),nrow=length(data$FalsePos),byrow=T)),
#             (matrix(unlist(data$TruePos),nrow=length(data$TruePos),byrow=T)))
# 
# names(dat) <- c('FalsePos','TruePos')
# 
# numOfSub = length(unique(data$sub))
# numOfTrial = dim(dat$FalsePos)[1]
# lengthOfTime = dim(dat$FalsePos)[2]
# timeLen = c(0,1)
# 
# ind_data_ROC = data.frame(
#   sub =  rep( data$sub, times = rep( lengthOfTime, numOfTrial)),
#   data_y = t(matrix(t(dat$TruePos),nrow=1)),
#   data_x = t(matrix(t(dat$FalsePos),nrow=1)),
#   lag = rep( as.character(data$lag), times = rep( lengthOfTime, numOfTrial)),
#   condition = rep( ggName[unlist(data$type)+1], times = rep( lengthOfTime, numOfTrial)),
#   exp = rep( ggName2[unlist(data$exp)], times = rep( lengthOfTime, numOfTrial))
# )
# ind_data_ROC$lag <- factor(ind_data_ROC$lag,levels =c("-20","-15","-10","-5","0","5","10","15","20"))
# ind_data_ROC = ind_data_ROC[ind_data_ROC$exp == 'e1' & ind_data_ROC$condition == 'Baseline' ,]
# ind_data_ROC = aggregate( . ~ lag, data = ind_data_ROC, FUN = "mean")
# 
# p = ggplot(ind_data_ROC,aes(x=data_y,y = data_x,group = interaction(sub,lag),color=lag))+
#   geom_line()+
#   annotate(x=0, xend=1, y=0, yend=1, colour="black", lwd=0.5, geom="segment")+
#   facet_wrap(sub ~ .)
# 
# 
# ind_data = data.frame(
#   sub = unlist(data$sub),
#   data_y =unlist( data$AUC),
#   lag = unlist(data$lag),
#   condition = ggName[unlist(data$type)+1],
#   exp = ggName2[unlist(data$exp)]
# )
# 
# dat_p = data.frame()
# for(iExp in 1:2){
#   
#   for (iCondition in 1:2){
#     pVal = NULL
#     for(iLag in unique(ind_data$lag)){
#       tmp = ind_data[ind_data$lag == iLag & 
#                        ind_data$exp == ggName2[iExp] &
#                        ind_data$condition == ggName[iCondition],]
#       d = t.test(tmp$data_y,mu=0.5, alternative="greater")
#       pVal = rbind(pVal,round(d[["p.value"]], digits = 4))
#     }
#     tmp_dat_p = data.frame(
#       pVal = p.adjust(pVal, method = "BH"),
#       data_y = 0,
#       data_x = unique(ind_data$lag),
#       condition = ggName[iCondition],
#       exp = ggName2[iExp]
#     )
#     dat_p = rbind(dat_p,tmp_dat_p)
#   }
# }
# 
# dat_p['flag'] = rep('gray',dim(dat_p)[1])
# ind = dat_p['pVal'] < 0.1 & dat_p['pVal'] > 0.05 & dat_p$condition == 'Baseline'
# dat_p['data_y'][ind] = 0.58
# dat_p['flag'][ind] = 'gray'
# 
# ind = dat_p['pVal'] < 0.1 & dat_p['pVal'] > 0.05 & dat_p$condition == 'Transient'
# dat_p['data_y'][ind] = 0.44
# dat_p['flag'][ind] = 'gray'
# 
# ind = dat_p['pVal'] < 0.05 & dat_p$condition == 'Baseline'
# dat_p['data_y'][ind] = 0.58
# dat_p['flag'][ind] = 'black'
# 
# ind = dat_p['pVal'] < 0.05 & dat_p$condition == 'Transient'
# dat_p['data_y'][ind] = 0.44
# dat_p['flag'][ind] = 'black'
# 
# ind_data_anova = ind_data[ind_data$exp == 'e1',]
# ind_data_anova$exp = NULL
# ind_data_anova = ind_data_anova[,c(1,3,4,2)]

```

# Results
## Experiment 1
### Behavioral response
Participants reported the number of perceptual alternations from 0 to 5. Since the trial numbers were unbalanced among these responses (__Fig. 1C__), we classified the number of alternation responses into 0, 1, and more than 2 times (hereafter, referred to as 0-, 1-, >1-alt cases, respectively). The average numbers of trials were 
`r ave_numOfTrial[ave_numOfTrial$numOfSwitch == '0',]$numOfTrial` $\pm$ `r sd_numOfTrial[sd_numOfTrial$numOfSwitch == '0',]$numOfTrial`, 
`r ave_numOfTrial[ave_numOfTrial$numOfSwitch == '1',]$numOfTrial` $\pm$ `r sd_numOfTrial[sd_numOfTrial$numOfSwitch == '1',]$numOfTrial`, and 
`r ave_numOfTrial[ave_numOfTrial$numOfSwitch == '2+',]$numOfTrial` $\pm$ `r sd_numOfTrial[sd_numOfTrial$numOfSwitch == '2+',]$numOfTrial`, respectively 
($F$(`r round(anovaTabAll_e1$numOfTrial$anovaTab[2,]['df.col'],2)`,`r round(anovaTabAll_e1$numOfTrial$anovaTab[3,]['df.col'],2)`) = 
`r round(anovaTabAll_e1$numOfTrial$anovaTab[2,]['f.col'],3)`, $p$ = `r round(anovaTabAll_e1$numOfTrial$anovaTab[2,]['p.col'],3)`, 
$\eta^2_p$ = `r round(anovaTabAll_e1$numOfTrial$anovaTab[2,]['p.eta^2'],3)`, $BF_{10}$ = `r anovaTabAll_e1$numOfTrial$bf`). 
Post analysis showed that the number of trials for 1-alt cases was significantly larger than for 0- and >1-alt cases 
($t$(`r anovaTabAll_e1$numOfTrial$post[3,]$df`) = `r round(anovaTabAll_e1$numOfTrial$post[3,]$t,3)`, 
$p$ = `r round(anovaTabAll_e1$numOfTrial$post[3,]$p.value, 3)`, 
Cohen’s  $d_z$ = `r anovaTabAll_e1$numOfTrial$cohen_pair0_1`, 
$BF_{10}$ =  `r anovaTabAll_e1$numOfTrial$bayesF_pair0_1`; 
$t$(`r anovaTabAll_e1$numOfTrial$post[1,]$df`) = `r round(anovaTabAll_e1$numOfTrial$post[1,]$t,3)`, 
$p$ = `r round(anovaTabAll_e1$numOfTrial$post[1,]$p.value, 3)`, 
Cohen’s  $d_z$ = `r anovaTabAll_e1$numOfTrial$cohen_pair1_2`, 
$BF_{10}$ =  `r anovaTabAll_e1$numOfTrial$bayesF_pair1_2`) and that for 0-alt cases was larger than for >1-alt cases 
($t$(`r anovaTabAll_e1$numOfTrial$post[2,]$df`) = `r round(anovaTabAll_e1$numOfTrial$post[2,]$t,3)`, 
$p$ = `r round(anovaTabAll_e1$numOfTrial$post[2,]$p.value, 3)`, 
Cohen’s  $d_z$ = `r anovaTabAll_e1$numOfTrial$cohen_pair0_2`, 
$BF_{10}$ =  `r anovaTabAll_e1$numOfTrial$bayesF_pair0_2`) 
at alpha level of 0.05/3 corrected by a Bonferroni-Holm method. 
RTs of each response category were 
`r rt_ave[rt_ave$numOfSwitch == 0,]$RT` $\pm$ `r rt_sd[rt_sd$numOfSwitch == 0,]$RT` sec, 
`r rt_ave[rt_ave$numOfSwitch == 1,]$RT` $\pm$ `r rt_sd[rt_sd$numOfSwitch == 1,]$RT` sec, and 
`r rt_ave[rt_ave$numOfSwitch == 2,]$RT` $\pm$ `r rt_sd[rt_sd$numOfSwitch == 2,]$RT` sec 
($F$(`r round(anovaTabAll_e1$RT_table$anovaTab[2,]['df.col'],2)`,`r round(anovaTabAll_e1$RT_table$anovaTab[3,]['df.col'],2)`) = `r round(anovaTabAll_e1$RT_table$anovaTab[2,]['f.col'],3)`, 
$p$ = `r round(anovaTabAll_e1$RT_table$anovaTab[2,]['p.col'],3)`, $\eta^2_p$ = `r round(anovaTabAll_e1$RT_table$anovaTab[2,]['p.eta^2'],3)`, $BF_{10}$ = `r anovaTabAll_e1$RT_table$bf`).
Although the observation period was jittered from 5-9 second, there was no statistical differences between the number of perceptual alternations and the observation time 
($F$(`r round(anovaTabAll_e1$jitter_table$anovaTab[2,]['df.col'],2)`,`r round(anovaTabAll_e1$jitter_table$anovaTab[3,]['df.col'],2)`) = `r round(anovaTabAll_e1$jitter_table$anovaTab[2,]['f.col'],3)`, 
$p$ = `r round(anovaTabAll_e1$jitter_table$anovaTab[2,]['p.col'],3)`, $\eta^2_p$ = `r round(anovaTabAll_e1$jitter_table$anovaTab[2,]['p.eta^2'],3)`, $BF_{10}$ = `r anovaTabAll_e1$jitter_table$bf`). 


### Baseline pupil size
__Figure 2A__ illustrates the grand-averaged baseline pupil changes across participants before the response cue onset, as a function of perceptual alternations number. The one-way repeated measures ANOVA revealed a significant main effect on the number of perceptual alternations 
($F$(`r round( anovaTabAll_e1$BP_table$anovaTab[2,]['df.col'],2)`,`r round( anovaTabAll_e1$BP_table$anovaTab[3,]['df.col'],2)`) = `r round( anovaTabAll_e1$BP_table$anovaTab[2,]['f.col'],3)`, 
$p$ = `r round( anovaTabAll_e1$BP_table$anovaTab[2,]['p.col'],3)`, $\eta^2_p$ = `r round( anovaTabAll_e1$BP_table$anovaTab[2,]['p.eta^2'],3)`, $BF_{10}$ = `r  anovaTabAll_e1$BP_table$bf`). 
The post-hoc multiple comparisons showed that the baseline pupil size in the >1-alt case was significantly larger than in the 0- and 1-alt cases 
($t$(`r numOfsub-1`) = `r round(anovaTabAll_e1$BP_table$post[2,]$t,3)`, $p$ = `r round(anovaTabAll_e1$BP_table$post[2,]$p.value,3)`, 
Cohen’s  $d_z$ = `r anovaTabAll_e1$BP_table$cohen_d0`, $BF_{10}$ =  `r anovaTabAll_e1$BP_table$bayesF_d0`; 
$t$(`r numOfsub-1`) = `r round(anovaTabAll_e1$BP_table$post[1,]$t,3)`, $p$ =  `r round(anovaTabAll_e1$BP_table$post[1,]$p.value,3)`, 
Cohen’s  $d_z$ = `r anovaTabAll_e1$BP_table$cohen_d1`, $BF_{10}$ =  `r anovaTabAll_e1$BP_table$bayesF_d1`, respectively), 
indicating that the baseline pupil size, prior to counting the number of alternations, was related to a subsequent number of perceptual transitions.
The answered number of trials was significantly different among the 0-, 1-, and >1 cases as shown above. Such unbalanced trial numbers can cause biases in the statistical analysis and decreased statistical power. Thus, we performed an alternative analysis to avoid this potential statistical problem. We segregated the trials equally into five bins based on the rank order of baseline pupil size. Results are shown in Fig. 2B. The data were fitted by a simple regression model 
($y$ = `r round(summary(anovaTabAll_e1$tertile_table$model)[['coefficients']]['a',]['Estimate'],3)`$x$ + `r round(summary(anovaTabAll_e1$tertile_table$model)[['coefficients']]['b',]['Estimate'],3)`, 
$R$ = `r round(anovaTabAll_e1$tertile_table$r[['estimate']][['cor']],3)`, $t$ = `r anovaTabAll_e1$tertile_table$tVal`, $p$ = `r anovaTabAll_e1$tertile_table$pVal`). 
Consistent with the previous results, the number of alternations monotonically increased with the baseline pupil size.


```{r, message=FALSE, warning=FALSE, echo=FALSE, include=FALSE}

go1 = c("unswitch","switch")

if(mmFlg){
  load("./data/Exp2/Figure3_mm.rda")
}else if(auFlg){
  load("./data/Exp2/figure3_au.rda")
}else{
  load("./data/Exp2/Figure3_norm.rda")
}

anovaTabAll_e2 = list()

#### Behavioral(RT) ----------------------------------------------------------------
# anovakun(data_RT,"sA",long=T, peta=T)
rt_sd = aggregate( RT ~ Responses, data = data_RT, FUN = "sd")
rt_ave = aggregate( RT ~ Responses, data = data_RT, FUN = "mean")
rt_sd$RT = round(rt_sd$RT,3)
rt_ave$RT = round(rt_ave$RT,3)

# RT_table = forDrawingSigANOVA
x = data_RT[data_RT$Responses == 0,]$RT
y = data_RT[data_RT$Responses == 1,]$RT
n = length(x)
RT_table = t.test(x,y,var.equal=T,paired=T)

bf = ttestBF(x = x, y = y, paired=TRUE)

RT_table = list(list(
  anovaTab = t.test(x,y,var.equal=T,paired=T),
  cohend = abs(round(RT_table[["statistic"]][["t"]] / sqrt(n),3)),
  bf = round(exp(bf@bayesFactor[["bf"]]),3)
))
names(RT_table) <- c('RT_table')

anovaTabAll_e2 = c(anovaTabAll_e2,RT_table)

#### Behavioral(number of switch and jitter) -----------------------------------------
saveLoc = "../[Python]PreProcessing/Exp2/data/"
dat_jitter=fromJSON(file=paste(saveLoc,"numOfSwitch_jitter.json", sep = ""))

ind_jitter <- data.frame(
  sub = unlist(dat_jitter$sub),
  Responses = unlist(dat_jitter$responses),
  jitter = unlist(dat_jitter$taskTimeLen)
)
dat_jitter = aggregate( . ~ sub*Responses, data = ind_jitter, FUN = "mean")

x = dat_jitter[dat_jitter$Responses == 0,]$jitter
y = dat_jitter[dat_jitter$Responses == 1,]$jitter
n = length(x)

jitter_table_e2 = t.test(x,y,var.equal=T,paired=T)

cohen_d = cohen.d(x,y,paired=TRUE, within=TRUE)
bf = ttestBF(x = x, y = y, paired=TRUE)

jitter_table = list(list(
  anovaTab = t.test(x,y,var.equal=T,paired=T),
  cohend = abs(round(jitter_table_e2[["statistic"]][["t"]] / sqrt(n),3)),
  bf = round(exp(bf@bayesFactor[["bf"]]),3)
))
names(jitter_table) <- c('jitter_table')

anovaTabAll_e2 = c(anovaTabAll_e2,jitter_table)

#### Behavioral(trials) ----------------------------------------------------------------
data_numOfTrial = aggregate( numOfTrial ~ sub*Responses, data = data_corr, FUN = "max")

ave_numOfTrial = aggregate( numOfTrial ~ Responses, data = data_numOfTrial, FUN = "mean")
ave_numOfTrial$numOfTrial = round(ave_numOfTrial$numOfTrial,2)
sd_numOfTrial = aggregate( numOfTrial ~ Responses, data = data_numOfTrial, FUN = "sd")
sd_numOfTrial$numOfTrial = round(sd_numOfTrial$numOfTrial,2)

x = data_numOfTrial[data_numOfTrial$Responses == 0,]$numOfTrial
y = data_numOfTrial[data_numOfTrial$Responses == 1,]$numOfTrial
n = length(x)

numOfTrial_e2_table = t.test(x,y,var.equal=T,paired=T)
bf = ttestBF(x = x, y = y, paired=TRUE)

numOfTrial_table = list(list(
  anovaTab = t.test(x,y,var.equal=T,paired=T),
  cohend = abs(round(numOfTrial_e2_table[["statistic"]][["t"]] / sqrt(n),3)),
  bf = round(exp(bf@bayesFactor[["bf"]]),3)
))
names(numOfTrial_table) <- c('numOfTrial_table')

anovaTabAll_e2 = c(anovaTabAll_e2,numOfTrial_table)

#### Figure 4A(# of switch) ####
numOfSub_e2 = length(unique(data_res$sub))

data_res$Responses = go1[data_res$Responses+1]
data_res$Responses = factor(data_res$Responses,levels = go1)

data_res = data_res[,c(1,2,4,3)]
data_res = data_res[data_res$type == 'size',]
data_res$type = NULL

x = data_res[data_res$Responses == "unswitch",]$data_y
y = data_res[data_res$Responses == "switch",]$data_y
n = length(x)

res = t.test(x,y,var.equal=T,paired=T)

tVal = round(res[["statistic"]][["t"]],3)
pVal = round(res[["p.value"]],3)

# cohen_d = cohen.d(x,y,paired=TRUE, within=TRUE)
bf = ttestBF(x = x, y = y, paired=TRUE)

BP_table = list(list(
  anovaTab = t.test(x,y,var.equal=T,paired=T),
  tVal =  round(res[["statistic"]][["t"]],3),
  pVal =  round(res[["p.value"]],3),
  cohend = abs(round(res[["statistic"]][["t"]] / sqrt(n),3)),
  bf = round(exp(bf@bayesFactor[["bf"]]),3)
))
names(BP_table) <- c('BP_table')

anovaTabAll_e2 = c(anovaTabAll_e2,BP_table)

#### Figure 4B(tertile) ####
if(mmFlg){
  data = fromJSON(file="../[Python]PreProcessing/Exp2/data/data_tertile_mm.json")
}else if(auFlg){
  data = fromJSON(file="../[Python]PreProcessing/Exp2/data/data_tertile_au.json")
}else{
  # data = fromJSON(file="../[Python]PreProcessing/Exp2/data/data_tertile20210610.json")
  data = fromJSON(file="../[Python]PreProcessing/Exp2/data/data_tertile_norm.json")
}

data_tertile_e2 = data.frame(
  sub = data$sub,
  Tertile = data$tertile,
  responses_sorted = data$responses_sorted,
  data_y = data$responses_sorted
)
data_tertile_e2 = aggregate( . ~ sub*Tertile, data = data_tertile_e2, FUN = "mean")

data_tertile_e2$sub = subName[data_tertile_e2$sub]

x = as.numeric(data_tertile_e2$Tertile)
y = data_tertile_e2$data_y
f <- y ~  a*x + b
model1 <- nls(f, start = c(a = 0, b = 0))

f <- y ~  a*x^2 + b*x + c
model2 <- nls(f, start = c(a = 0, b = 0, c=0))

if (AIC(model1) > AIC(model2)){
  model = model2
}else{
  model = model1
}
df <- data.frame(x = seq(1, 5, length = 10))
data_curve = data.frame(
  Tertile = df$x,
  yy = predict(model, df)
)


bf = regressionBF(data_y ~ Tertile, data = data_tertile_e2)

data_tertile_e2 = aggregate( . ~ sub*Tertile, data = data_tertile_e2, FUN = "mean")
r_e2 = cor.test(x,y)

f = data.frame(
  sub = as.character(unique(data_tertile_e2$sub)),
  x = data_tertile_e2$Tertile,
  y = data_tertile_e2$responses_sorted
)

tertile_table = list(list(
  r = cor.test(x,y),
  tVal = round(summary(model)[["coefficients"]]['a',]['t value'],4),
  pVal = round(summary(model)[["coefficients"]]['a',]['Pr(>|t|)'],4),
  model = model,
  bf = round(exp(bf@bayesFactor[["bf"]]),3)
))
names(tertile_table) <- c('tertile_table')

anovaTabAll_e2 = c(anovaTabAll_e2,tertile_table)


#### Figure 5 ####
load('./data/dataset_figure5_2.rda')

# ind_data = ind_data[ind_data$events == 'dilation',]
# data_ave = aggregate( data_y ~ sub*numOfSwitch*exp, data = ind_data, FUN = "mean")

numOfSub = length(unique(data_anovaPD$sub))
f = data.frame(
  sub = as.character(unique(data_anovaPD$sub)),
  y = matrix(data_anovaPD$data_y,nrow = numOfSub)
)

colnames(f) <- c("subject",c('Exp1-unswitch','Exp1-switch','Exp2-unswitch','Exp2-switch'))
write.csv(f, "../[JASP]Bayesian/data_anovaPD.csv",row.names=FALSE)

anovakun(data_anovaPD,"sAB",long=T, peta=T,gg=T)
event_PD_table = forDrawingSigANOVA

data_anovaPD$numOfSwitch = factor(data_anovaPD$numOfSwitch,levels = unique(data_anovaPD$numOfSwitch))
data_anovaPD$exp = factor(data_anovaPD$exp,levels = unique(data_anovaPD$exp))
data_anovaPD$sub = factor(data_anovaPD$sub,levels = unique(data_anovaPD$sub))

data_anovaPD_BF = anovaBF(data_y ~ numOfSwitch*exp + sub, data=data_anovaPD, whichRandom = "sub")
data_anovaPD_BF = round(exp(data_anovaPD_BF@bayesFactor[["bf"]]),3)

anovakun(data_anovaPC,"sAB",long=T, peta=T,gg=T)
event_PC_table = forDrawingSigANOVA

data_anovaPC$numOfSwitch = factor(data_anovaPC$numOfSwitch,levels = unique(data_anovaPC$numOfSwitch))
data_anovaPC$exp = factor(data_anovaPC$exp,levels = unique(data_anovaPC$exp))
data_anovaPC$sub = factor(data_anovaPC$sub,levels = unique(data_anovaPC$sub))

data_anovaPC_BF = anovaBF(data_y ~ numOfSwitch*exp + sub, data=data_anovaPC, whichRandom = "sub")
data_anovaPC_BF = round(exp(data_anovaPC_BF@bayesFactor[["bf"]]),3)

```


## Experiment 2
### Behavioral response
The average number of ‘yes’ and ‘no’ trials (presence and absence of perceptual alternations, respectively) were 
`r ave_numOfTrial[ave_numOfTrial$Responses == 0,]$numOfTrial` $\pm$ `r sd_numOfTrial[sd_numOfTrial$Responses == '0',]$numOfTrial` and 
`r ave_numOfTrial[ave_numOfTrial$Responses == '1',]$numOfTrial` $\pm$ `r sd_numOfTrial[sd_numOfTrial$Responses == '1',]$numOfTrial`, respectively 
($t$(1,`r anovaTabAll_e2$numOfTrial_table$anovaTab[["parameter"]][["df"]]`) = `r round(anovaTabAll_e2$numOfTrial_table$anovaTab[["statistic"]][["t"]],3)`, $p$ = `r round(anovaTabAll_e2$numOfTrial_table$anovaTab[["p.value"]],3)`, Cohen’s  $d_z$ = `r anovaTabAll_e2$numOfTrial_table$cohend`). 
Again, there was no statistical differences between 'yes' or 'no' trial and the observation time 
($t$(1,`r anovaTabAll_e2$jitter_table$anovaTab[["parameter"]][["df"]]`) = `r round(anovaTabAll_e2$jitter_table$anovaTab[["statistic"]][["t"]],3)`, $p$ = `r round(anovaTabAll_e2$jitter_table$anovaTab[["p.value"]],3)`, Cohen’s  $d_z$ = `r anovaTabAll_e2$jitter_table$cohend`). 
RT in the answer ‘yes’ (`r rt_ave[rt_ave$Responses == 0,]$RT` $\pm$ `r rt_sd[rt_sd$Responses == 0,]$RT` s) was significantly faster than ‘no’ (`r rt_ave[rt_ave$Responses == 0,]$RT` $\pm$ `r rt_sd[rt_sd$Responses == 0,]$RT` s)  
($t$(1,`r anovaTabAll_e2$RT_table$anovaTab[["parameter"]][["df"]]`) = `r round(anovaTabAll_e2$RT_table$anovaTab[["statistic"]][["t"]],3)`, $p$ = `r round(anovaTabAll_e2$RT_table$anovaTab[["p.value"]],3)`, Cohen’s  $d_z$ = `r anovaTabAll_e2$RT_table$cohend`). This could be because, the participant in the ‘yes’ trial would have been ready to respond as soon as the first occurrence of a perceptual alternation before the response cue was presented, whereas the participant had to wait until the cue to say ‘no’. It is important to note, therefore, that the perceptual load and/or mental effort is expected to be lower in the ‘yes’ trials than in the ‘no’ ones. In Experiment 1, the participant had to keep counting and memorizing the number of alternations throughout the observation period, possibly leading to increasing perceptual load in the trials with increasing number of alternations. Thus, there was a concern that the association between the pupil size and number of perceptual alternations observed in Experiment 1 reflected such a perceptual load, rather than the processes involved in perceptual switching. The current yes/no paradigm serves as a control test to evaluate the confounding effect of this task-related perceptual load. 

### Baseline pupil size
Figure 3A shows the grand-averaged time-course of baseline pupil changes parameterized by alternation cases (yes or no). Consistent with Experiment 1, a paired t-test for averaged changes in baseline pupil size from -1000 ms to the response cue onset for each answer (i.e., the presence or absence of perceptual alternation) showed that the baseline pupil size in the presence of a perceptual alternation was significantly larger than in the absence of perceptual alternation 
($t$(`r numOfSub_e2-1`) = `r round(anovaTabAll_e2$BP_table$tVal[1],3)`, $p$ = `r round(anovaTabAll_e2$BP_table$pVal[1],3)`, Cohen’s  $d_z$ = `r anovaTabAll_e2$BP_table$cohend`, $BF_{10}$ =  `r anovaTabAll_e2$BP_table$bf`).


Following the same analysis procedure as in Experiment 1, we segregated the trials into five bins based on the ranked order of the normalized baseline pupil size. For each participant, we normalized the probability of perceptual alternation by z-scores and averaged them in each pupil size bin (Fig. 3B). The model fitted by a simple regression showed the significance 
($y$ = `r round(summary(anovaTabAll_e2$tertile_table$model)[['coefficients']]['a',]['Estimate'],3)`$x$ + `r round(summary(model)[['coefficients']]['b',]['Estimate'],3)`, $R$ = `r round(anovaTabAll_e2$tertile_table$r[['estimate']][['cor']],3)`, $t$ = `r anovaTabAll_e2$tertile_table$tVal`, $p$ = `r anovaTabAll_e2$tertile_table$pVal`).


<!-- ### Correlation heatmap -->
<!-- As a further analysis, we calculated the correlation between the number of switch and several eye-metrics (__Figure 2C__); besides the significant correlation with baseline pupil size ($R$ = `r melted_data[melted_data$L1 == 'numOfSwitch' & melted_data$L2 == 'Baseline',]$value`, $p$ = `r melted_data[melted_data$L1 == 'numOfSwitch' & melted_data$L2 == 'Baseline',]$p.value`), besides the significant positive correlation between the number of switch and baseline pupil size ($R$ = `r melted_data[melted_data$L1 == 'Transient' & melted_data$L2 == 'Baseline',]$value`, $p$ = `r melted_data[melted_data$L1 == 'Transient' & melted_data$L2 == 'Baseline',]$p.value`). Since the pupil change is mediated by the dilater/sphincter muscle in the iris, this might be interpreted as a trade-off mechanism of the iris musculature or activation of ANS  __(Joshi et al., 2016)__. -->
## Transient Pupil Dilation/Constriction (PD/PC)
To assess the relationship between perceptual alternations and transient pupil change reported previously (Einhäuser et al., 2008; Grenzebach et al., 2021; Turi et al., 2018), we calculated the rate of PD/PC events (see Methods). Figure 4A shows the occurrence of PD/PC events for each trial across all subjects, over a period of 2 s before the task response to 4 s after it. We averaged the number of PD events over a period of 4 s after the task response (Fig. 4B). To compare by the within-subject design, the participants who were not rejected in both Experiments 1 and 2 were examined in the following analysis. Two-way repeated measures ANOVAs on the averaged PD events with the response content and experiment as within-subject factors revealed that the average number of PD event was significantly larger in alternation trials than in no-alternation trials
($F$(`r round(event_PD_table[2,]['df.col'],2)`,`r round(event_PD_table[3,]['df.col'],2)`) = `r round(event_PD_table[2,]['f.col'],3)`, 
$p$ = `r round(event_PD_table[2,]['p.col'],3)`, $\eta^2_p$ = `r round(event_PD_table[2,]['p.eta^2'],3)`, $BF_{10}$ =  `r  data_anovaPD_BF[1]`), 
consistent with the previous studies (Einhäuser et al., 2008; Grenzebach et al., 2021). 
The number of PD events was larger in Experiment 1 than in 2 
($F$(`r round(event_PD_table[4,]['df.col'],2)`,`r round(event_PD_table[5,]['df.col'],2)`) = `r round(event_PD_table[4,]['f.col'],3)`, 
$p$ = `r round(event_PD_table[4,]['p.col'],3)`, $\eta^2_p$ = `r round(event_PD_table[4,]['p.eta^2'],3)`, $BF_{10}$ =  `r  data_anovaPD_BF[2]`), 
which could be explained by the higher task demand in Experiment 1, as the LC-NE system reflects a broad range of cognitive processes. There was no interaction between the response content and experiment 
($F$(`r round(event_PD_table[6,]['df.col'],2)`,`r round(event_PD_table[7,]['df.col'],2)`) = `r round(event_PD_table[6,]['f.col'],3)`, 
$p$ = `r round(event_PD_table[6,]['p.col'],3)`, $\eta^2_p$ = `r round(event_PD_table[6,]['p.eta^2'],3)`, $BF_{10}$ =  `r  round(data_anovaPD_BF[4]/data_anovaPD_BF[3],3)`). 
Two-way repeated measures ANOVAs on the averaged PC showed that there were no significant main effect and interaction 
($F$(`r round(event_PC_table[2,]['df.col'],3)`,`r round(event_PC_table[3,]['df.col'],3)`) = `r round(event_PC_table[2,]['f.col'],3)`, 
$p$ = `r round(event_PC_table[2,]['p.col'],3)`, $\eta^2_p$ = `r round(event_PC_table[2,]['p.eta^2'],3)`, $BF_{10}$ =  `r  data_anovaPC_BF[1]`); 
$F$(`r round(event_PC_table[4,]['df.col'],3)`,`r round(event_PC_table[5,]['df.col'],3)`) = `r round(event_PC_table[4,]['f.col'],3)`, 
$p$ = `r round(event_PC_table[4,]['p.col'],3)`, $\eta^2_p$ = `r round(event_PC_table[4,]['p.eta^2'],3)`, $BF_{10}$ =  `r  data_anovaPC_BF[2]`; 
$F$(`r round(event_PC_table[6,]['df.col'],3)`,`r round(event_PC_table[7,]['df.col'],3)`) = `r round(event_PC_table[6,]['f.col'],3)`, 
$p$ = `r round(event_PC_table[6,]['p.col'],3)`, $\eta^2_p$ = `r round(event_PC_table[6,]['p.eta^2'],3)`, $BF_{10}$ =  `r  round(data_anovaPC_BF[4]/data_anovaPC_BF[3],3)`, respectively).
There was a concern that the PD events and observed baseline pupil size were not sufficiently independent measures. For example, if the transient pupil dilation had a sufficiently slow time decay, the apparent baseline diameter would build up with accumulated PD events. To address this concern that the baseline pupil size might be affected by the PD events, we calculated the number of PD events in the baseline pupil size analysis in every 1-s time bin (Supplementary Fig. 2) and the correlation between the baseline pupil size and number of transient PD events (Supplementary Fig. 3). Note that the number of PD events during the early 4-s part of the observation period were summed and their order ranked across trials for each subject. The baseline pupil size after the window for calculating the number of PD events was parameterized by the rank order of the PD events. The results revealed that there was no statistical evidence that increasing the number of PD events can explain the baseline pupil size in both experiments.


## Cross-correlation function
The cross-correlation analysis (Fig. 5) revealed that the baseline pupil size and the number of perceptual alternations had a significant positive correlation over the range of nine trials; -6 to +3 trials with a lag of around 0. This result can be interpreted as indicating that the baseline pupil size at least 35 s (= 5 s x 6 trials + 5 s; see below) before the behavioral response predicts perceptual alternation and the overall correspondence between pupil size and the number of perceptual alternations is sustained for at least 45 s (5 s x 9 trials). It should be recalled that for a given trial (or the lag of 0 in Fig. 5), the window for deriving the baseline pupil size preceded the corresponding response by the duration of the observation period (therefore, an additional 5 s was included to derive the 35-s period), and that the observation period was varied randomly between 5 and 9 s (Fig. 1D, red line). Thus, the 35-s and 45-s durations shown above are conservative estimates, with the assumption that the representative observation period was the minimum of the randomization range. 



<!-- Each trial lasted for 5-7 s, segregated by a response cue to ask for behavioral responses. In the cross-correlation analysis, we aligned the timing of behavioral response and pupil size throughout the experimental session (see Method). Cross-correlation functions between the changes in baseline pupil size and the number of perceptual switches were calculated in every single subject. We found that the number of switches was positively correlated with the pupil size up to 5 trials (nearly 25 to 35 s) ahead of the response time (Figure 3A). The maximum cross-correlation coefficient in raw cross-correlation was significantly higher than in shuffled (__Figure 3A__). -->
<!-- The maximum cross-correlation coefficient in raw cross-correlation was significantly higher than in shuffled  ($t$(1, `r numOfsub-1`) = `r round(CCF_max[["statistic"]][["t"]],3)`, $p$ = `r round(CCF_max[["p.value"]], 3)`, Cohen’s  $d_z$ = `r CCF_max_cohen_d`, $BF_{10}$ =  `r CCF_max_bayesF`). Furthermore, the averaged lag at peak correlation was significantly shifted to negative ($t$(1, `r numOfsub-1`) = `r round(CCF_lag[["statistic"]][["t"]],3)`, $p$ = `r round(CCF_lag[["p.value"]], 3)`, $BF_{10}$ =  `r CCF_lag_bayesF`) (__Figure 3C__). -->

<!-- ### Liner mixed modeling and ROC curve -->
<!-- In this section, we focused on (a) how long the baseline pupil size effect on the number of perceptual switches at a certain trial lasts, (b) variability within participants, (c) classification accuracy. To address these, we calculated beta weights using a linear mixed-model (LMM) (Figure 3D) regarded the number of perceptual switches as dependent variable, the baseline pupil size as fixed effect and participants as random effect. For each trial, LMM was performed repeatedly changing the baseline pupil size data adopted from -20 to 20 trials corresponding to the answer at a certain trial. In consistent with the cross-correlation analysis, the LMM revealed a significant positive correlation between the number of switch and the baseline pupil size with not larger individual differences at least from -7 to 0 trial (i.e., 30s). Furthermore, the detection performance was quantified by the area under the curve (AUC) using receiver operating characteristic (ROC) curves (Figure 3E). Wilcoxon rank-sum test showed that the AUC from -5 to 5 trial were significantly greater than chance level (i.e., 0.5). -->

<!-- $CCF(\tau) = \frac{Cov(P(t),N_{switch}(t+\tau))}{\sigma_{P(t)}\sigma_{N_{switch}(t+\tau)}}$  -->

<!-- ### PC events -->
<!-- Main effect on alternation -->
<!-- Main effect on experiments  -->
<!-- Interaction -->
<!-- ($F$(1,`r round(event_PC_table[1,]['df.col'],3)`) = `r round(event_PC_table[2,]['f.col'],3)`, $p$ = `r round(event_PC_table[2,]['p.col'],3)`, $\eta^2_p$ = `r round(event_PC_table[2,]['p.eta^2'],3)`; $F$(1,`r round(event_PC_table[3,]['df.col'],3)`) = `r round(event_PC_table[4,]['f.col'],3)`, $p$ = `r round(event_PC_table[4,]['p.col'],3)`, $\eta^2_p$ = `r round(event_PC_table[4,]['p.eta^2'],3)`; $F$(1,`r round(event_PC_table[5,]['df.col'],3)`) = `r round(event_PC_table[6,]['f.col'],3)`, $p$ = `r round(event_PC_table[6,]['p.col'],3)`, $\eta^2_p$ = `r round(event_PC_table[6,]['p.eta^2'],3)`). -->

### Statistical analysis
Mean baseline pupil size was subjected to a one-way repeated-measures analysis of variance (ANOVA) with the number of alternations as the within-subject factor in Experiment 1. A paired t-tests was applied to the mean baseline pupil size between the presence (alternation) and absence (no- alternation) of perceptual alternations in Experiment 2. The level of statistical significance was set to p < 0.05 for all analyses. Pairwise comparisons of the main effects were corrected through multiple comparisons using the Bonferroni-Holm method. Effect sizes were given as partial $\eta^2$; $\eta^2_p$ for ANOVA and as Cohen’s d_z for t-tests __(Cohen, 1988, p.48; Lakens, 2013)__. Greenhouse–Geisser corrections were performed when the results of Mauchly’s sphericity test were significant. To quantify the evidence in the data, we performed Bayesian paired t-tests with a Cauchy prior width of r = 0.707 for effect size using the BayesFactor package (v0.9.12-4.2) __(Morey, 2019)__ for the R software (Version 3.6.3) __(R Core Team, 2020)__. Bayesian Factor (BF) estimates the relative weight of the evidence in favor of $H_1$ over $H_0$ as $BF_{10}$


For baseline pupil size bin analysis, for each participant, all trials were sorted in ascending order based on the baseline pupil size and divided into five equally populated bins. This procedure led to an equal trial number in each pupil size bin. The number of perceptual alternations (Experiment 1) and the z-scored probability of perceptual alternation (Experiment 2) was averaged and fitted by the following two models to assess whether the behavioral variability (Y) can be explained by a monotonic fitting or second-order polynomials.


Model 1 : $Y = \beta_0 + \beta_1P$

Model 2 : $Y = \beta_0 + \beta_1P + \beta_2P^2$


where $\beta$ represents regression coefficients, and $P$ represents the baseline pupil response bins. The models were quantified using the Akaike information criterion (AIC), which specifies the evidence of goodness of fit for a model.

<!-- In Experiment 1, the value of Pearson’s correlation was calculated at a lag between the pupil size and the normalized number of switches using $z$-score in cross-correlation. $p$ values for Pearson’s correlation were corrected by FDR for multiple comparisons using the Benjamini and Hochberg method __(Benjamini and Hochberg, 1995)__. -->


<!-- We used a linear mixed-effects modeling (LMM) with participant as a random effect to calculate the correlation between the individuals' baseline pupil size ($\vec{P}_{n}$) and the number of perceptual switch ($\vec{S_n}$) in Experiment 1 as follwing model, using the lme4 packages __(Bates et al., 2015)__. -->

<!-- $[S_i]_{n+t},(-t < i < n) \sim \alpha_t + \beta_t * [P_i]_{n+t},(0 < i < n+t) + N(0,\sigma_{participant}),(t \leq 0)$ -->

<!-- $[S_i]_{n+t},(0 < i < n-t) \sim \alpha_t + \beta_t * [P_i]_{n+t},(t < i < n ) + N(0,\sigma_{participant}),(t > 0)$ -->

<!-- where $\beta$ as beta weight and $n$ as indivisuals' total number of trials. The analyzed period was $-20 \leq t \leq 20$ -->


<!-- ### Pupil dilation/constriction events analysis -->
<!-- Pupil slope was computed using second order central differences after applying 1 s window of smoothing filter within a trial. Pupil dilation and constriction events were defined as maximum positive and negative values of the slope, separeted by $\leq$ 300 ms (__Joshi et al., 2016; Zhao et al., 2019__). The analysis interval was from 2 s before to 5 s after the task response. For each trial, the number of dilation events were summed and then all averaged between switch and unswitch condition in each participant. -->